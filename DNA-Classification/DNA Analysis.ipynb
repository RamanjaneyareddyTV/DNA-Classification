{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNA Sequences Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bacteria and other micro-organisms have been very import for the field of biology.\n",
    "In this project E. Coli Bacteria DNA nucleotide sequences have been classified based on its Promoter class.\n",
    "\n",
    "We shall explore the world of Bioinformatics by using Markov models, K-nearest neighbor (KNN) algorithms, Support Vector Machines (widely used), adaboost algorithm, Decision tree, Random forest classifier and such more algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally we shall test our data based on the training data model and compare the results of all the algorithms through classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.8 (tags/v3.9.8:bb3fdcf, Nov  5 2021, 20:48:33) [MSC v.1929 64 bit (AMD64)]\n",
      "Numpy: 1.21.5\n",
      "Sklearn: 1.0.2\n",
      "Pandas: 1.4.1\n"
     ]
    }
   ],
   "source": [
    "# Lets start with importing all the required modules and packages and ensure their versions\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Numpy: {}'.format(np.__version__))\n",
    "print('Sklearn: {}'.format(sklearn.__version__))\n",
    "print('Pandas: {}'.format(pd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step:1 Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving further lets import our data from UCI machine learning repo\n",
    "\n",
    "url = 'F:/New folder/Compressed/DNA-Classification-master/Dataset/promoters.data'\n",
    "\n",
    "# Explicitly defining the features(columns) of our data\n",
    "col_names = ['Class','id','Sequence']\n",
    "\n",
    "data  =pd.read_csv(url,names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>id</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+</td>\n",
       "      <td>S10</td>\n",
       "      <td>\\t\\ttactagcaatacgcttgcgttcggtggttaagtatgtataat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+</td>\n",
       "      <td>AMPC</td>\n",
       "      <td>\\t\\ttgctatcctgacagttgtcacgctgattggtgtcgttacaat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+</td>\n",
       "      <td>AROH</td>\n",
       "      <td>\\t\\tgtactagagaactagtgcattagcttatttttttgttatcat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+</td>\n",
       "      <td>DEOP2</td>\n",
       "      <td>\\taattgtgatgtgtatcgaagtgtgttgcggagtagatgttagaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+</td>\n",
       "      <td>LEU1_TRNA</td>\n",
       "      <td>\\ttcgataattaactattgacgaaaagctgaaaaccactagaatgc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class         id                                           Sequence\n",
       "0     +        S10  \\t\\ttactagcaatacgcttgcgttcggtggttaagtatgtataat...\n",
       "1     +       AMPC  \\t\\ttgctatcctgacagttgtcacgctgattggtgtcgttacaat...\n",
       "2     +       AROH  \\t\\tgtactagagaactagtgcattagcttatttttttgttatcat...\n",
       "3     +      DEOP2  \\taattgtgatgtgtatcgaagtgtgttgcggagtagatgttagaa...\n",
       "4     +  LEU1_TRNA  \\ttcgataattaactattgacgaaaagctgaaaaccactagaatgc..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'a', 'c', 't', 'a', 'g', 'c', 'a', 'a', 't', 'a', 'c', 'g', 'c', 't', 't', 'g', 'c', 'g', 't', 't', 'c', 'g', 'g', 't', 'g', 'g', 't', 't', 'a', 'a', 'g', 't', 'a', 't', 'g', 't', 'a', 't', 'a', 'a', 't', 'g', 'c', 'g', 'c', 'g', 'g', 'g', 'c', 't', 't', 'g', 't', 'c', 'g', 't', '+']\n"
     ]
    }
   ],
   "source": [
    "# We now see here that our data has tab spaces between id and sequence, thus we see '\\t' in front of Sequence string\n",
    "\n",
    "# removing those extra charaters from sequence string\n",
    "classes = data.loc[:, 'Class']\n",
    "sequences = list(data.loc[:,'Sequence'])\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "for i, seq in enumerate(sequences):\n",
    "    \n",
    "    nucleotides = list(seq)\n",
    "    nucleotides = [x for x in nucleotides if x != '\\t']\n",
    "    \n",
    "    nucleotides.append(classes[i])\n",
    "    \n",
    "    dataset[i] = nucleotides\n",
    "    \n",
    "print(dataset[0])\n",
    "# Here we get all the sequence of DNA base pairs (like a:adenine, t:thymine, g:guanine, c:cytosine)\n",
    "# Also the last term is the class our nucleotide(promotor class either +/-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0   1   2   3   4   5   6   7   8   9    ... 96  97  98  99  100 101 102  \\\n",
      "0   t   t   g   a   t   a   c   t   c   t  ...   c   c   t   a   g   c   g   \n",
      "1   a   g   t   a   c   g   a   t   g   t  ...   c   g   a   g   a   c   t   \n",
      "2   c   c   a   t   g   g   g   t   a   t  ...   g   c   t   a   g   t   a   \n",
      "3   t   t   c   t   a   g   g   c   c   t  ...   a   t   g   g   a   c   t   \n",
      "4   a   a   t   g   t   g   g   t   t   a  ...   g   a   a   g   g   a   t   \n",
      "\n",
      "  103 104 105  \n",
      "0   c   c   t  \n",
      "1   g   t   a  \n",
      "2   c   c   a  \n",
      "3   g   g   c  \n",
      "4   a   t   a  \n",
      "\n",
      "[5 rows x 106 columns]\n"
     ]
    }
   ],
   "source": [
    "# now moving on lets convert the above dict into pandas dataframe\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  1  2  3  4  5  6  7  8  9   ... 48 49 50 51 52 53 54 55 56 57\n",
      "0  t  a  c  t  a  g  c  a  a  t  ...  g  c  t  t  g  t  c  g  t  +\n",
      "1  t  g  c  t  a  t  c  c  t  g  ...  c  a  t  c  g  c  c  a  a  +\n",
      "2  g  t  a  c  t  a  g  a  g  a  ...  c  a  c  c  c  g  g  c  g  +\n",
      "3  a  a  t  t  g  t  g  a  t  g  ...  a  a  c  a  a  a  c  t  c  +\n",
      "4  t  c  g  a  t  a  a  t  t  a  ...  c  c  g  t  g  g  t  a  g  +\n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# Above dataframe doesn't look what we wanted so try and transpose it\n",
    "\n",
    "df = df.transpose()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4  5  6  7  8  9  ... 48 49 50 51 52 53 54 55 56 Class\n",
      "0  t  a  c  t  a  g  c  a  a  t  ...  g  c  t  t  g  t  c  g  t     +\n",
      "1  t  g  c  t  a  t  c  c  t  g  ...  c  a  t  c  g  c  c  a  a     +\n",
      "2  g  t  a  c  t  a  g  a  g  a  ...  c  a  c  c  c  g  g  c  g     +\n",
      "3  a  a  t  t  g  t  g  a  t  g  ...  a  a  c  a  a  a  c  t  c     +\n",
      "4  t  c  g  a  t  a  a  t  t  a  ...  c  c  g  t  g  g  t  a  g     +\n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# Changing the column name 57 to Class for better readability\n",
    "df.rename(columns={57: 'Class'},inplace=True) \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    +\n",
      "1    +\n",
      "2    +\n",
      "3    +\n",
      "4    +\n",
      "Name: Class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Now it looks more better with each column till 56 representing \n",
    "# base pairs of DNA (adenine,thymine, guanine, cytosine) and last column is of promotor class\n",
    "\n",
    "# What our final aim was also to predict the promotor class of the DNA sequence\n",
    "test = df.iloc[:,-1]\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start to familiarize ourselves with the dataset so we can pick the most suitable algorithms for this data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>t</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9  ...   48   49   50  \\\n",
       "count   106  106  106  106  106  106  106  106  106  106  ...  106  106  106   \n",
       "unique    4    4    4    4    4    4    4    4    4    4  ...    4    4    4   \n",
       "top       t    a    a    c    a    a    a    a    a    a  ...    c    c    c   \n",
       "freq     38   34   30   30   36   42   38   34   33   36  ...   36   42   31   \n",
       "\n",
       "         51   52   53   54   55   56 Class  \n",
       "count   106  106  106  106  106  106   106  \n",
       "unique    4    4    4    4    4    4     2  \n",
       "top       t    t    c    c    c    t     +  \n",
       "freq     33   35   32   29   29   34    53  \n",
       "\n",
       "[4 rows x 58 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2     3     4     5     6     7     8     9  ...    48  \\\n",
      "t  38.0  26.0  27.0  26.0  22.0  24.0  30.0  32.0  32.0  28.0  ...  21.0   \n",
      "c  27.0  22.0  21.0  30.0  19.0  18.0  21.0  20.0  22.0  22.0  ...  36.0   \n",
      "a  26.0  34.0  30.0  22.0  36.0  42.0  38.0  34.0  33.0  36.0  ...  23.0   \n",
      "g  15.0  24.0  28.0  28.0  29.0  22.0  17.0  20.0  19.0  20.0  ...  26.0   \n",
      "+   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "-   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "\n",
      "     49    50    51    52    53    54    55    56  Class  \n",
      "t  22.0  23.0  33.0  35.0  30.0  23.0  29.0  34.0    NaN  \n",
      "c  42.0  31.0  32.0  21.0  32.0  29.0  29.0  17.0    NaN  \n",
      "a  24.0  28.0  27.0  25.0  22.0  26.0  24.0  27.0    NaN  \n",
      "g  18.0  24.0  14.0  25.0  22.0  28.0  24.0  28.0    NaN  \n",
      "+   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   53.0  \n",
      "-   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   53.0  \n",
      "\n",
      "[6 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# Describe doesn't tell much when our data is of object(text) datatype, so we should count the number of each seq.\n",
    "\n",
    "val_count = []\n",
    "\n",
    "for name in df.columns:\n",
    "    val_count.append(df[name].value_counts())\n",
    "\n",
    "info = pd.DataFrame(val_count)\n",
    "info = info.transpose()\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0_a  0_c  0_g  0_t  1_a  1_c  1_g  1_t  2_a  2_c  ...  55_a  55_c  55_g  \\\n",
      "0    0    0    0    1    1    0    0    0    0    1  ...     0     0     1   \n",
      "1    0    0    0    1    0    0    1    0    0    1  ...     1     0     0   \n",
      "2    0    0    1    0    0    0    0    1    1    0  ...     0     1     0   \n",
      "3    1    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
      "4    0    0    0    1    0    1    0    0    0    0  ...     1     0     0   \n",
      "\n",
      "   55_t  56_a  56_c  56_g  56_t  Class_+  Class_-  \n",
      "0     0     0     0     0     1        1        0  \n",
      "1     0     1     0     0     0        1        0  \n",
      "2     0     0     0     1     0        1        0  \n",
      "3     1     0     1     0     0        1        0  \n",
      "4     0     0     0     1     0        1        0  \n",
      "\n",
      "[5 rows x 230 columns]\n"
     ]
    }
   ],
   "source": [
    "# Our dataset has equal counts of both the classes promotor(+) as well as non-promotor(-)\n",
    "\n",
    "# But knowing all this then too we can't apply ML models directly on data in 'String' formats\n",
    "# So we need to convert object datatype into that of numerical data type \n",
    "\n",
    "# Let's use pandas get_dummies function for that\n",
    "numerical_df = pd.get_dummies(df)\n",
    "print(numerical_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0_a  0_c  0_g  0_t  1_a  1_c  1_g  1_t  2_a  2_c  ...  54_t  55_a  55_c  \\\n",
      "0    0    0    0    1    1    0    0    0    0    1  ...     0     0     0   \n",
      "1    0    0    0    1    0    0    1    0    0    1  ...     0     1     0   \n",
      "2    0    0    1    0    0    0    0    1    1    0  ...     0     0     1   \n",
      "3    1    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
      "4    0    0    0    1    0    1    0    0    0    0  ...     1     1     0   \n",
      "\n",
      "   55_g  55_t  56_a  56_c  56_g  56_t  Class  \n",
      "0     1     0     0     0     0     1      1  \n",
      "1     0     0     1     0     0     0      1  \n",
      "2     0     0     0     0     1     0      1  \n",
      "3     0     1     0     1     0     0      1  \n",
      "4     0     0     0     0     1     0      1  \n",
      "\n",
      "[5 rows x 229 columns]\n"
     ]
    }
   ],
   "source": [
    "# Great! but we see that our class is also divided into 2 columns though it is only has binary categories\n",
    "\n",
    "df = numerical_df.drop(columns=['Class_-'])\n",
    "\n",
    "df.rename(columns = {'Class_+': 'Class'}, inplace=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Spliting our data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_4420\\1715802424.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X = np.array(df.drop(['Class'], 1))\n"
     ]
    }
   ],
   "source": [
    "# Using Train test split from sklearn.model_selection\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Create X as features and y as label\n",
    "X = np.array(df.drop(['Class'], 1))\n",
    "y = np.array(df['Class'])\n",
    "\n",
    "# defining seed for reproducibility\n",
    "seed = 1\n",
    "\n",
    "# spliting data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Applying Machine learning algorithms to our training sets\n",
    "\n",
    "Now that we have preprocessed the data and built our training and testing datasets, we can start to deploy different classification algorithms. It's relatively easy to test multiple models; as a result, we will compare and contrast the performance of ten different algorithms on some performance metrics such as accuracy_score and classification_report (best way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m names \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name,model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m---> 45\u001b[0m     kfold \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_selection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     cv_results \u001b[38;5;241m=\u001b[39m model_selection\u001b[38;5;241m.\u001b[39mcross_val_score(model,X_train,y_train,cv\u001b[38;5;241m=\u001b[39mkfold,scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m     47\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(cv_results)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:435\u001b[0m, in \u001b[0;36mKFold.__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m*\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 435\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296\u001b[0m, in \u001b[0;36m_BaseKFold.__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshuffle must be True or False; got \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shuffle))\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shuffle \u001b[38;5;129;01mand\u001b[39;00m random_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# None is the default\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting a random_state has no effect since shuffle is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalse. You should leave \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_state to its default (None), or set shuffle=True.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    300\u001b[0m     )\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m=\u001b[39m n_splits\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshuffle \u001b[38;5;241m=\u001b[39m shuffle\n",
      "\u001b[1;31mValueError\u001b[0m: Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# We can start building algorithms! We'll need to import each algorithm we plan on using from sklearn.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# defining scoring method\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# we have 10 models to train\n",
    "names = [\"Nearest Neighbors\", \"Random Forest\",\"Neural Net\",\n",
    "         \"Decision Tree\",\"AdaBoost\",\"Gaussian Process\",\n",
    "         \"Naive Bayes\", \"SVM Linear\", \"SVM RBF\", \"SVM Sigmoid\"]\n",
    "\n",
    "# lets define each of the classifier\n",
    "classifier = [\n",
    "    KNeighborsClassifier(n_neighbors=3),\n",
    "    RandomForestClassifier(n_estimators=10,max_depth=5,max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianProcessClassifier(1.0*RBF(1.0)),\n",
    "    GaussianNB(),\n",
    "    SVC(kernel = 'linear'),\n",
    "    SVC(kernel = 'rbf'),\n",
    "    SVC(kernel='sigmoid')\n",
    "]\n",
    "\n",
    "models = zip(names,classifier)\n",
    "\n",
    "# evaluate models\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name,model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10,random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model,X_train,y_train,cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    formating = \"%s: %f (%f)\" %(name, cv_results.mean(),cv_results.std())\n",
    "    print(formating)\n",
    "    print(\"Testing Scores\")\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(name)\n",
    "    \n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember, performance on the training data is not that important. We want to know how well our algorithms can generalize to new data.\n",
    "\n",
    "### Finally, **SVM linear** performs the best and also it is not that surprising because, the reason SVM is used in the field of Bioinformatics widely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definations of attributes in classification report\n",
    "Accuracy - ratio of correctly predicted observation to the total observations. \n",
    "\n",
    "Precision - (false positives) ratio of correctly predicted positive observations to the total predicted positive observations\n",
    "\n",
    "Recall (Sensitivity) - (false negatives) ratio of correctly predicted positive observations to the all observations in actual class - yes.\n",
    "\n",
    "F1 score - F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
